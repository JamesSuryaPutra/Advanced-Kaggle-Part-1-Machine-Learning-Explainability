<Setup>
At this point, you have enough tools to put together compelling solutions to real-world problems. You will ned to pick the right techniques for each part of the following data science
scenario. Along the way, you'll use SHAP values along with your other insights tools.

The questions below give you feedback on your work by using some checking code. Run the following cell to set up our feedback system.

****************
# Get most recent checking code
!pip install -U -t /kaggle/working/ git+https://github.com/Kaggle/learntools.git
from learntools.ml_explainability.ex4 import *
print("Setup Complete")

Collecting git+https://github.com/Kaggle/learntools.git
  Cloning https://github.com/Kaggle/learntools.git to /tmp/pip-req-build-pt4rzjy2
  Running command git clone --filter=blob:none --quiet https://github.com/Kaggle/learntools.git /tmp/pip-req-build-pt4rzjy2
  Resolved https://github.com/Kaggle/learntools.git to commit 940f894c224b3737a597a80e9a792face28c6562
  Preparing metadata (setup.py) ... done
Building wheels for collected packages: learntools
  Building wheel for learntools (setup.py) ... done
  Created wheel for learntools: filename=learntools-0.3.4-py3-none-any.whl size=268968 sha256=9f4a98bdcb325e474b55b531003ae781be06d2fa568ccc3bd5336825b8ff3181
  Stored in directory: /tmp/pip-ephem-wheel-cache-1vp4pkiz/wheels/2f/6c/3c/aa9f50cfb5a862157cb4c7a5b34881828cf45404698255dced
Successfully built learntools
Installing collected packages: learntools
Successfully installed learntools-0.3.4
Setup Complete
****************

<The scenario>
A hospital has struggled with "readmissions," where they release a patient before the patient has recovered enough, and the patient returns with health complications. The hospital wants
your help identifying patients at highest risk of being readmitted. Doctors (rather than your model) will make the final decision about when to release each patient; but they hope your
model will highlight issues the doctors should consider when releasing a patient.

The hospital has given you relevant patient medical information. Here is a list of columns in the data.

****************
import pandas as pd
data = pd.read_csv('../input/hospital-readmissions/train.csv')
data.columns

Index(['time_in_hospital', 'num_lab_procedures', 'num_procedures',
       'num_medications', 'number_outpatient', 'number_emergency',
       'number_inpatient', 'number_diagnoses', 'race_Caucasian',
       'race_AfricanAmerican', 'gender_Female', 'age_[70-80)', 'age_[60-70)',
       'age_[50-60)', 'age_[80-90)', 'age_[40-50)', 'payer_code_?',
       'payer_code_MC', 'payer_code_HM', 'payer_code_SP', 'payer_code_BC',
       'medical_specialty_?', 'medical_specialty_InternalMedicine',
       'medical_specialty_Emergency/Trauma',
       'medical_specialty_Family/GeneralPractice',
       'medical_specialty_Cardiology', 'diag_1_428', 'diag_1_414',
       'diag_1_786', 'diag_2_276', 'diag_2_428', 'diag_2_250', 'diag_2_427',
       'diag_3_250', 'diag_3_401', 'diag_3_276', 'diag_3_428',
       'max_glu_serum_None', 'A1Cresult_None', 'metformin_No',
       'repaglinide_No', 'nateglinide_No', 'chlorpropamide_No',
       'glimepiride_No', 'acetohexamide_No', 'glipizide_No', 'glyburide_No',
       'tolbutamide_No', 'pioglitazone_No', 'rosiglitazone_No', 'acarbose_No',
       'miglitol_No', 'troglitazone_No', 'tolazamide_No', 'examide_No',
       'citoglipton_No', 'insulin_No', 'glyburide-metformin_No',
       'glipizide-metformin_No', 'glimepiride-pioglitazone_No',
       'metformin-rosiglitazone_No', 'metformin-pioglitazone_No', 'change_No',
       'diabetesMed_Yes', 'readmitted'],
      dtype='object')
****************

Here are some quick hints at interpreting the field names:
1} Your prediction target is readmitted.
2} Columns with the word diag indicate the diagnostic code of the illness or illnesses the patient was admitted with. For example, diag_1_428 means the doctor said their first illness
diagnosis is number "428". What illness does 428 correspond to? You could look it up in a codebook, but without more medical background it wouldn't mean anything to you anyway.
3} A column names like glimepiride_No mean the patient did not have the medicine glimepiride. If this feature had a value of False, then the patient did take the drug glimepiride.
4} Features whose names begin with medical_specialty describe the specialty of the doctor seeing the patient. The values in these fields are all True or False.

<Your code library>
As you write code to work through this scenario, these code snippets from previous tutorials may be useful. You'll still need to modify them, but we've copied them here to save you from
having to look them up.

Calculate and show permutation importance:
================
import eli5
from eli5.sklearn import PermutationImportance

perm = PermutationImportance(my_model, random_state=1).fit(val_X, val_y)
eli5.show_weights(perm, feature_names = val_X.columns.tolist())
================

Calculate and show partial dependence plot:
================
from matplotlib import pyplot as plt
from sklearn.inspection import PartialDependenceDisplay

feature_name = 'Goal Scored'
PartialDependenceDisplay.from_estimator(my_model, val_X, [feature_name])
plt.show()
================

Calculate and show Shap Values for One Prediction:
================
import shap  # package used to calculate Shap values

data_for_prediction = val_X.iloc[0,:]  # use 1 row of data here. Could use multiple rows if desired

# Create object that can calculate shap values
explainer = shap.TreeExplainer(my_model)
shap_values = explainer.shap_values(data_for_prediction)
shap.initjs()
shap.force_plot(explainer.expected_value[0], shap_values[0], data_for_prediction)
================

<Step 1>
You have built a simple model, but the doctors say they don't know how to evaluate a model, and they'd like you to show them some evidence the model is doing something in line with
their medical intuition. Create any graphics or tables that will show them a quick overview of what the model is doing?

They are very busy. So they want you to condense your model overview into just 1 or 2 graphics, rather than a long string of graphics. We'll start after the point where you've built
a basic model. Just run the following cell to build the model called my_model.

****************
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
​
data = pd.read_csv('../input/hospital-readmissions/train.csv')
​
y = data.readmitted
​
base_features = [c for c in data.columns if c != "readmitted"]
​
X = data[base_features]
​
train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)
my_model = RandomForestClassifier(n_estimators=30, random_state=1).fit(train_X, train_y)
****************

Now use the following cell to create the materials for the doctors.

****************
# Your code here
import eli5
from eli5.sklearn import PermutationImportance

perm = PermutationImportance(my_model, random_state=1).fit(val_X, val_y)
eli5.show_weights(perm, feature_names = val_X.columns.tolist())

Weight	Feature
0.0451 ± 0.0068	number_inpatient
0.0087 ± 0.0046	number_emergency
0.0062 ± 0.0053	number_outpatient
0.0033 ± 0.0016	payer_code_MC
0.0020 ± 0.0016	diag_3_401
0.0016 ± 0.0031	medical_specialty_Emergency/Trauma
0.0014 ± 0.0024	A1Cresult_None
0.0014 ± 0.0021	medical_specialty_Family/GeneralPractice
0.0013 ± 0.0010	diag_2_427
0.0013 ± 0.0011	diag_2_276
0.0011 ± 0.0022	age_[50-60)
0.0010 ± 0.0022	age_[80-90)
0.0007 ± 0.0006	repaglinide_No
0.0006 ± 0.0010	diag_1_428
0.0006 ± 0.0022	payer_code_SP
0.0005 ± 0.0030	insulin_No
0.0004 ± 0.0028	diabetesMed_Yes
0.0004 ± 0.0021	diag_3_250
0.0003 ± 0.0018	diag_2_250
0.0003 ± 0.0015	glipizide_No
… 44 more …

For our idea of what to show, run the cell below.

# Run this code cell to receive credit!
q_1.solution()

Solution:
# Use permutation importance as a succinct model summary
# A measure of model performance on validation data would be useful here too

import eli5
from eli5.sklearn import PermutationImportance

perm = PermutationImportance(my_model, random_state=1).fit(val_X, val_y)
eli5.show_weights(perm, feature_names = val_X.columns.tolist())
****************

<Step 2>
It appears number_inpatient is a really important feature. The doctors would like to know more about that. Create a graph for them that shows how num_inpatient affects the model's
predictions.

****************
# Your Code Here
from matplotlib import pyplot as plt
from sklearn.inspection import PartialDependenceDisplay
​
feature_name = 'number_inpatient'
PartialDependenceDisplay.from_estimator(my_model, val_X, [feature_name])
plt.show()

For our solution, run the line below.

# Check your answer (Run this code cell to receive credit!)
q_2.solution()

Solution:
# PDP for number_inpatient feature

from matplotlib import pyplot as plt
from sklearn.inspection import PartialDependenceDisplay

feature_name = 'number_inpatient'
PartialDependenceDisplay.from_estimator(my_model, val_X, [feature_name])
plt.show()
****************

<Step 3>
The doctors think it's a good sign that increasing the number of inpatient procedures leads to increased predictions. But they can't tell from this plot whether that change in the plot
is big or small. They'd like you to create something similar for time_in_hospital to see how that compares.

****************
# Your Code Here
from matplotlib import pyplot as plt
from sklearn.inspection import PartialDependenceDisplay
​
feature_name = 'time_in_hospital'
PartialDependenceDisplay.from_estimator(my_model, val_X, [feature_name])
plt.show()

Uncomment the relevant line below to see one solution.

# Check your answer (Run this code cell to receive credit!)
q_3.solution()

Solution:
The results are very different. Specifically time in hospital has a much smaller effect. Code below:
from matplotlib import pyplot as plt
from sklearn.inspection import PartialDependenceDisplay

feature_name = 'time_in_hospital'
PartialDependenceDisplay.from_estimator(my_model, val_X, [feature_name])
plt.show()
****************

<Step 4>
Woah! It seems like time_in_hospital doesn't matter at all. The difference between the lowest value on the partial dependence plot and the highest value is about 5%. If that is, what
your model concluded, the doctors will believe it. But it seems so low. Could the data be wrong, or is your model doing something more complex than they expect?

They'd like you to show them the raw readmission rate for each value of time_in_hospital to see how it compares to the partial dependence plot:
1} Make that plot.
2} Are the results similar or different?

****************
# Your Code Here
all_train = pd.concat([train_X, train_y], axis=1)

all_train.groupby(['time_in_hospital']).mean().readmitted.plot()
plt.show()

For a hint, uncomment the line below.

q_4.hint()

Hint:
This requires a groupby (from pandas) on the raw data, rather than using a model.

# Check your answer (Run this code cell to receive credit!)
q_4.solution()

Solution:
# A simple pandas groupby showing the average readmission rate for each time_in_hospital.

# Do concat to keep validation data separate, rather than using all original data
all_train = pd.concat([train_X, train_y], axis=1)

all_train.groupby(['time_in_hospital']).mean().readmitted.plot()
plt.show()
****************

<Step 5>
Now the doctors are convinced you have the right data, and the model overview looked reasonable. It's time to turn this into a finished product they can use. Specifically, the hospital
wants you to create a function patient_risk_factors that does the following:
1} Takes a single row with patient data (of the same format you as your raw data).
2} Creates a visualization showing what features of that patient increased their risk of readmission, what features decreased it, and how much those features mattered.

It's not important to show every feature with every miniscule impact on the readmission risk. It's fine to focus on only the most important features for that patient.

****************
# Your Code Here
import shap

sample_data_for_prediction = val_X.iloc[0].astype(float)

def patient_risk_factors(model, patient_data):
    explainer = shap.TreeExplainer(model)
    shap_values = explainer.shap_values(patient_data)
    shap.initjs()
    return shap.force_plot(explainer.expected_value[1], shap_values[1], patient_data)

For a hint, uncomment the line below.

q_5.hint()

Hint:
Here's the time to use SHAP values.

# Check your answer (Run this code cell to receive credit!)
q_5.solution()

Solution:
# Use SHAP values to show the effect of each feature of a given patient

import shap  # package used to calculate Shap values

sample_data_for_prediction = val_X.iloc[0].astype(float)  # to test function

def patient_risk_factors(model, patient_data):
    # Create object that can calculate shap values
    explainer = shap.TreeExplainer(model)
    shap_values = explainer.shap_values(patient_data)
    shap.initjs()
    return shap.force_plot(explainer.expected_value[1], shap_values[1], patient_data)
****************
